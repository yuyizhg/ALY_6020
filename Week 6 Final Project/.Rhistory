nrow(data)
data[is.na(data$ca) | is.na(data$thal),]
## so 6 of the 303 rows of data have missing values. This isn't a large
## percentage (2%), so we can just remove them from the dataset
## NOTE: This is different from when we did machine learning with
## Random Forests. When we did that, we imputed values.
nrow(data)
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data)
# Logistic Regression
logistic <- glm(hd ~ ., data=data, family="binomial")
summary(logistic)
## Now calculate the overall "Pseudo R-squared" and its p-value
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
## McFadden's Pseudo R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)
(ll.null - ll.proposed) / ll.null
## The p-value for the R^2
1 - pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
## now we can plot the data
predicted.data <- data.frame(
probability.of.hd=logistic$fitted.values,
hd=data$hd)
predicted.data <- predicted.data[
order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
## Lastly, we can plot the predicted probabilities for each sample having
## heart disease and color by whether or not they actually had heart disease
ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
geom_point(aes(color=hd), alpha=1, shape=4, stroke=2) +
xlab("Index") +
ylab("Predicted probability of getting heart disease")
ggsave("heart_disease_probabilities.pdf")
## Now determine how many rows have "NA" (aka "Missing data"). If it's just
## a few, we can remove them from the dataset, otherwise we should consider
## imputing the values with a Random Forest or some other imputation method.
nrow(data[is.na(data$ca) | is.na(data$thal),])
data[is.na(data$ca) | is.na(data$thal),]
## Now we can do some quality control by making sure all of the factor
## levels are represented by people with and without heart disease (hd)
xtabs(~ hd + sex, data=data)
xtabs(~ hd + cp, data=data)
xtabs(~ hd + fbs, data=data)
xtabs(~ hd + restecg, data=data)
xtabs(~ hd + exang, data=data)
xtabs(~ hd + slope, data=data)
xtabs(~ hd + ca, data=data)
xtabs(~ hd + thal, data=data)
# k-NN
str(data)
round(prop.table(table(data$hd)) * 100, digits = 1)
View(data)
View(data)
summary(data[c('sexM', 'cp', 'trestbps', 'ca')])
summary(data[c('sex', 'cp', 'trestbps', 'ca')])
table(data$hd)
data_train <- data[train_sample, ]
## Data preparation - creating random training and test datasets
set.seed(123)
train_sample <- sample(1000, 900)
data_train <- data[train_sample, ]
data_test <- data[-train_sample, ]
prop.table(table(data_train$hd))
prop.table(table(data_test$hd))
## Training a model on the data
library(C50)
data_model <- C5.0(data_train[-14], data_train$hd)
data_model
summary(data_model)
## Evaluating model performance
data_pred <- predict(data_model, data_test)
## Evaluating model performance
library(gmodels)
CrossTable(data_test$hd, data_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('healthy', 'unhealthy'))
CrossTable(data_test$hd, data_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('yes', 'no'))
CrossTable(data_test$hd, data_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predict', 'actual'))
CrossTable(data_test$hd, data_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
## improving model performance
### Boosting the accuracy of decision trees
data_boost10 <- C5.0(data_train[-14], data_train$hd,
trials = 10)
data_boost10
summary(data_boost10)
data_boost10_pred10 <- predict(data_boost10, data_test)
CrossTable(data_test$hd, data_boost10_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
### Making mistakes more costlier than others
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
error_cost
data_cost <- C5.0(data_train[-21], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
CrossTable(data_test$hd, data_cost_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
CrossTable(data_test$hd, data_cost_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
error_cost
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
CrossTable(data_test$hd, data_cost_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
matrix_dimensions
# Random Forests
## Training a model on the data
set.seed(17)
data.rf <- randomForest(type ~ ., data = data,
mtry = 3, importance = TRUE,
do.trace = 100)
# Random Forests
## Training a model on the data
library(randomForest)
library(MASS)
data.rf <- randomForest(type ~ ., data = data,
mtry = 3, importance = TRUE,
do.trace = 100)
data.rf <- randomForest(hd ~ ., data = data,
mtry = 3, importance = TRUE,
do.trace = 100)
data.rf <- randomForest(hd ~ ., data = data,
mtry = 4, importance = TRUE,
do.trace = 100)
## evaluating model performance
print(data.rf)
## improving model performance
# Model Comparison with Errorest Functions
library(ipred)
set.seed(131)
error.RF <- numeric(10)
for (i in 1:10) error.RF[i] <-
errorest(hd ~ ., data = data,
model = randomForest, mtry = 4)$error
summary(error.RF)
library(e1071)
set.seed(563)
error.SVM <- numeric(10)
for (i in 1:10) error.SVM[i] <-
errorest(hd ~ ., data = data,
model = svm, cost = 10, gamma = 1.5)$error
summary(error.SVM)
par(mfrow = c(2, 2))
for (i in 1:4) {
plot(sort(data.rf$importance[,i], dec = TRUE),
type = "h", main = paste("Measure", i))
}
# Logistic Regression
logistic <- glm(hd ~ ., data=data, family="binomial")
summary(logistic)
## Now calculate the overall "Pseudo R-squared" and its p-value
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
## McFadden's Pseudo R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)
(ll.null - ll.proposed) / ll.null
## The p-value for the R^2
1 - pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
## now we can plot the data
predicted.data <- data.frame(
probability.of.hd=logistic$fitted.values,
hd=data$hd)
predicted.data <- predicted.data[
order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
## Lastly, we can plot the predicted probabilities for each sample having
## heart disease and color by whether or not they actually had heart disease
ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
geom_point(aes(color=hd), alpha=1, shape=4, stroke=2) +
xlab("Index") +
ylab("Predicted probability of getting heart disease")
## Check for class bias
table(Data$hd)
## Check for class bias
table(data$hd)
## Create training and test samples
### Create Training Data
data_ones <- inputData[which(data$hd == 'Healthy'), ]
## Create training and test samples
### Create Training Data
data_ones <- data[which(data$hd == 'Healthy'), ]
data_zeros <- data[which(data$hd == 'Unhealthy'), ]
set.seed(100)
data_ones_training_rows <- sample(1:nrow(data_ones), 0.7 * nrow(data_ones))
data_zeros_training_rows <- sample(1:nrow(data_zeros), 0.7 * nrow(data_ones))
training_ones <- data_ones[data_ones_training_rows, ]
training_zeros <- data_zeros[data_zeros_training_rows, ]
trainingData <- rbind(training_ones, training_zeros)
### Create Test Data
test_ones <- data_ones[-data_ones_training_rows, ]
test_zeros <- data_zeros[-data_zeros_training_rows, ]
testData <- rbind(test_ones, test_zeros)
## Compute information value to find out important variables
library(smbinning)
factor_vars <- c ("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")
continuous_vars <- c("age", "trestbps", "chol", "thalach", "oldpeak", "ca")
iv_df <- data.frame(VARS=c(factor_vars, continuous_vars), IV=numeric(13))
### compute IV for categoricals
for(factor_var in factor_vars){
smb <- smbinning.factor(trainingData, y="above50k", x=factor_var)  # WOE table
if(class(smb) != "character"){ # heck if some error occured
iv_df[iv_df$VARS == factor_var, "IV"] <- smb$iv
}
}
### compute IV for continuous vars
for(continuous_var in continuous_vars){
smb <- smbinning(trainingData, y="above50k", x=continuous_var)  # WOE table
if(class(smb) != "character"){  # any error while calculating scores.
iv_df[iv_df$VARS == continuous_var, "IV"] <- smb$iv
}
}
iv_df <- iv_df[order(-iv_df$IV), ]
iv_df
smb <- smbinning.factor(trainingData, y="hd", x=factor_var)  # WOE table
### compute IV for categoricals
for(factor_var in factor_vars){
smb <- smbinning.factor(trainingData, y="hd", x=factor_var)  # WOE table
if(class(smb) != "character"){ # heck if some error occured
iv_df[iv_df$VARS == factor_var, "IV"] <- smb$iv
}
}
### compute IV for continuous vars
for(continuous_var in continuous_vars){
smb <- smbinning(trainingData, y="hd", x=continuous_var)  # WOE table
if(class(smb) != "character"){  # any error while calculating scores.
iv_df[iv_df$VARS == continuous_var, "IV"] <- smb$iv
}
}
iv_df <- iv_df[order(-iv_df$IV), ]
iv_df
View(iv_df)
View(trainingData)
View(data)
summary(logistic)
library(ggplot2)
library(cowplot)
data <- read.csv("heart disease.csv")
# Data Preparation
head(data)
colnames(data) <- c(
"age",
"sex",# 0 = female, 1 = male
"cp", # chest pain
# 1 = typical angina,
# 2 = atypical angina,
# 3 = non-anginal pain,
# 4 = asymptomatic
"trestbps", # resting blood pressure (in mm Hg)
"chol", # serum cholestoral in mg/dl
"fbs",  # fasting blood sugar if less than 120 mg/dl, 1 = TRUE, 0 = FALSE
"restecg", # resting electrocardiographic results
# 1 = normal
# 2 = having ST-T wave abnormality
# 3 = showing probable or definite left ventricular hypertrophy
"thalach", # maximum heart rate achieved
"exang",   # exercise induced angina, 1 = yes, 0 = no
"oldpeak", # ST depression induced by exercise relative to rest
"slope", # the slope of the peak exercise ST segment
# 1 = upsloping
# 2 = flat
# 3 = downsloping
"ca", # number of major vessels (0-3) colored by fluoroscopy
"thal", # this is short of thalium heart scan
# 3 = normal (no cold spots)
# 6 = fixed defect (cold spots during rest and exercise)
# 7 = reversible defect (when cold spots only appear during exercise)
"hd" # (the predicted attribute) - diagnosis of heart disease
# 0 if less than or equal to 50% diameter narrowing
# 1 if greater than 50% diameter narrowing
)
head(data)
head(data)
str(data)
## First, convert "?"s to NAs...
data[data == "?"] <- NA
data[data$sex == 0,]$sex <- "F"
data[data$sex == 1,]$sex <- "M"
data$sex <- as.factor(data$sex)
data$cp <- as.factor(data$cp)
data$fbs <- as.factor(data$fbs)
data$restecg <- as.factor(data$restecg)
data$exang <- as.factor(data$exang)
data$slope <- as.factor(data$slope)
data$ca <- as.integer(data$ca) # since this column had "?"s in it
# R thinks that the levels for the factor are strings, but
# we know they are integers, so first convert the strings to integiers...
data$ca <- as.factor(data$ca)  # ...then convert the integers to factor levels
data$thal <- as.integer(data$thal) # "thal" also had "?"s in it.
data$thal <- as.factor(data$thal)
## This next line replaces 0 and 1 with "Healthy" and "Unhealthy"
data$hd <- ifelse(test=data$hd == 0, yes="Healthy", no="Unhealthy")
data$hd <- as.factor(data$hd) # Now convert to a factor
str(data)
## Now determine how many rows have "NA" (aka "Missing data"). If it's just
## a few, we can remove them from the dataset, otherwise we should consider
## imputing the values with a Random Forest or some other imputation method.
nrow(data[is.na(data$ca) | is.na(data$thal),])
data[is.na(data$ca) | is.na(data$thal),]
nrow(data)
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data)
## Now we can do some quality control by making sure all of the factor
## levels are represented by people with and without heart disease (hd)
xtabs(~ hd + sex, data=data)
xtabs(~ hd + cp, data=data)
xtabs(~ hd + fbs, data=data)
xtabs(~ hd + restecg, data=data)
xtabs(~ hd + exang, data=data)
xtabs(~ hd + slope, data=data)
xtabs(~ hd + ca, data=data)
xtabs(~ hd + thal, data=data)
# Decision Trees
str(data)
table(data$hd)
## Data preparation - creating random training and test datasets
set.seed(123)
train_sample <- sample(1000, 900)
data_train <- data[train_sample, ]
data_test <- data[-train_sample, ]
prop.table(table(data_train$hd))
prop.table(table(data_test$hd))
## Training a model on the data
library(C50)
data_model <- C5.0(data_train[-14], data_train$hd)
data_model
summary(data_model)
## Evaluating model performance
library(gmodels)
data_pred <- predict(data_model, data_test)
CrossTable(data_test$hd, data_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
## improving model performance
### Boosting the accuracy of decision trees
data_boost10 <- C5.0(data_train[-14], data_train$hd,
trials = 10)
data_boost10
summary(data_boost10)
data_boost10_pred10 <- predict(data_boost10, data_test)
CrossTable(data_test$hd, data_boost10_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
## Making mistakes more costlier than others
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
error_cost
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
data_cost <- C5.0(data_train[ ,-14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
error_cost
data_cost <- C5.0(data_train[ ,-14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
data_cost <- C5.0(data_train[, -14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
error_cost
data_cost <- C5.0(data_train[, -14], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
data_cost <- C5.0(data_train[, -13], data_train$hd,
costs = error_cost)
data_cost_pred <- predict(data_cost, data_test)
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost, trials=10)
data_cost_pred <- predict(data_cost, data_test)
# Decision Trees
str(data)
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
View(data_train)
error_cost
data_train$hd
data_train[-14]
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
summary(data_cost)
levels(data_train$hd)
levels(data_train[-14])
levels(error_cost)
levels(data_train[-14])[1]="missing"
levels(data_train[-14])
data_cost <- C5.0(data_train[-14], data_train$hd,
costs = error_cost)
summary(data_cost)
levels(data_train[-14])
data_train[-14]
data_train[-14]
levels(error_cost)
levels(data_train$hd)
levels(data_train$age)
levels(data_train$sex)
levels(data_train$cp)
levels(data_train$trestbps)
levels(data_train$chol)
levels(data_train$fbs)
data_train[2]
levels(data_train[2])
levels(data_train[1])
levels(data_train[0])
levels(data_train[3])
data_train[2]
data_cost <- C5.0(data_train[2], data_train$hd,
costs = error_cost)
summary(data_cost)
data_train$hd
data_train$sex
data_cost <- C5.0(data_train$sex, data_train$hd,
costs = error_cost)
data_train
data_train[2]
data_train[14]
levels(data_train[14])
# Random Forests
## Training a model on the data
library(randomForest)
library(MASS)
set.seed(17)
data.rf <- randomForest(hd ~ ., data = data,
mtry = 4, importance = TRUE,
do.trace = 100)
data.rf <- randomForest(hd ~ ., data = data,
mtry = 3, importance = TRUE,
do.trace = 100)
# Random Forests
## Training a model on the data
library(randomForest)
library(MASS)
set.seed(17)
data.rf <- randomForest(hd ~ ., data = data,
mtry = 3, importance = TRUE,
do.trace = 100)
## evaluating model performance
print(data.rf)
## improving model performance
# Model Comparison with Errorest Functions
library(ipred)
set.seed(131)
error.RF <- numeric(10)
for (i in 1:10) error.RF[i] <-
errorest(hd ~ ., data = data,
model = randomForest, mtry = 4)$error
summary(error.RF)
library(e1071)
set.seed(563)
error.SVM <- numeric(10)
for (i in 1:10) error.SVM[i] <-
errorest(hd ~ ., data = data,
model = svm, cost = 10, gamma = 1.5)$error
summary(error.SVM)
error.RF <- numeric(10)
for (i in 1:10) error.RF[i] <-
errorest(hd ~ ., data = data,
model = randomForest, mtry = 3)$error
summary(error.RF)
# Logistic Regression
logistic <- glm(hd ~ ., data=data, family="binomial")
summary(logistic)
## now we can plot the data
predicted.data <- data.frame(
probability.of.hd=logistic$fitted.values,
hd=data$hd)
predicted.data <- predicted.data[
order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
## Lastly, we can plot the predicted probabilities for each sample having
## heart disease and color by whether or not they actually had heart disease
ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
geom_point(aes(color=hd), alpha=1, shape=4, stroke=2) +
xlab("Index") +
ylab("Predicted probability of getting heart disease")
## confusion matrix
logistic
predicted.data
## confusion matrix
CrossTable(data$hd, predicted.data,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
View(predicted.data)
## confusion matrix
CrossTable(data$hd, predicted.data$hd,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual', 'predicted'))
str(data)
